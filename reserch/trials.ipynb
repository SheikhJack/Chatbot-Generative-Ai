{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a9fe8a3",
   "metadata": {},
   "source": [
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91a1aca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c207500a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Hello\\\\Desktop\\\\All Files\\\\python\\\\flask\\\\Chatbot-Generative-Ai\\\\reserch'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a815e69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59d0e6cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Hello\\\\Desktop\\\\All Files\\\\python\\\\flask\\\\Chatbot-Generative-Ai'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58ff5b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11e20d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract Data From the PDF File\n",
    "def load_pdf_file(data):\n",
    "    loader = DirectoryLoader(data,\n",
    "                             glob=\"*.pdf\",\n",
    "                             loader_cls=PyPDFLoader)\n",
    "    documents=loader.load()\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20307577",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data=load_pdf_file(data=\"Data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a76d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9aa64bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the Data into Text Chuncks\n",
    "def text_split(extracted_data):\n",
    "    text_splitter=RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "    text_chunks=text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe2faa69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text Chunks 6973\n"
     ]
    }
   ],
   "source": [
    "text_chunks=text_split(extracted_data)\n",
    "print(\"Length of text Chunks\", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedd28a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c12e95ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "323ae416",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download the Embeddings from Huggin Face\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings=HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf2ebc8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hello\\AppData\\Local\\Temp\\ipykernel_2924\\2851663624.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings=HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
      "c:\\Users\\Hello\\Desktop\\All Files\\python\\flask\\Chatbot-Generative-Ai\\medibot\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "embeddings = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ad84cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 384\n"
     ]
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(\"hello world\")\n",
    "print(\"Length\", len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fc09208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "117529ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "PINECONE_API_KEY = os.environ.get('PINECONE_API_KEY')\n",
    "GOOGLE_API_KEY = os.environ.get('GOOGLE_API_KEY')\n",
    "\n",
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2fdb9e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "import os\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "index = pc.Index(\"medibot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4b712abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efeec9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=text_chunks,\n",
    "    index_name=\"medibot\",\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "87426a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load existig index\n",
    "\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "#Embed each chunk and upsert the embeddings into Pinecone index\n",
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    index_name=\"medibot\",\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2ce7f995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_pinecone.vectorstores.PineconeVectorStore at 0x1b75152e480>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3bf810f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0eb3b8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "appearance are also signs of V on Willebrandâ€™s disease.\n",
      "Hypoprothrombinemia\n",
      "This disorder is a deficiency in prothrombin, or Factor\n",
      "II, a glycoprotein formed and stored in the liver. Prothrom-\n",
      "bin, under the right conditions, is converted to thrombin,\n",
      "which activates fibrin and begins the process of coagula-\n",
      "tion. Some patients may show no symptoms, and others\n",
      "will suffer severe hemorrhaging. Patients may experience\n",
      "easy bruising, profuse nosebleeds, postpartum hemorrhage,\n"
     ]
    }
   ],
   "source": [
    "docs = docsearch.similarity_search(\"acromegaly\", k=1)\n",
    "print(docs[0].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6a3ad6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am sorry, but the definition of acromegaly and gigantism are not in the context I was given.\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-001\")\n",
    "\n",
    "rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=docsearch.as_retriever(),\n",
    "    chain_type=\"stuff\"\n",
    ")\n",
    "\n",
    "response = rag_chain.invoke({\"query\": \"What is acromegaly and gigantism?\"})\n",
    "print(response[\"result\"])  # or print(response) to explore the structure\n",
    "\n",
    "\n",
    "\n",
    "# from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# llm = ChatGoogleGenerativeAI(\n",
    "#     model=\"gemini-2.0-flash\",\n",
    "#     temperature=0,\n",
    "#     max_tokens=None,\n",
    "#     timeout=None,\n",
    "#     max_retries=2,\n",
    "#     google_api_key=\"GOOGLE_API_KEY\" \n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "04902200",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant fro question-answering tasks.\"\n",
    "    \"Use the following pieces of retrievad context to answer\"\n",
    "    \"the question. If you don't know the answer, say that you\"\n",
    "    \"don't know. Use three sentences maximum and keep the\"\n",
    "    \"answer concise\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1a19931b",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c49f9a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonic irrigation involves cleansing the colon using hydrotherapy. It has been used for decades to relieve chronic toxicity and acute cases of toxemia. Over time, a thick layer of fecal matter can coat the colon, harden, and reduce bowel efficiency.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"what is Colonic irrigation \"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3e9a2988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOOGLE_API_KEY: AIzaSyBj10M6JS59OYf7AIEJKfwAWcL5vFZpgco\n"
     ]
    }
   ],
   "source": [
    "print(\"GOOGLE_API_KEY:\", os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99858d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I help you today?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"\"\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "model = genai.GenerativeModel(\"gemini-2.0-flash\")  \n",
    "response = model.generate_content(\"Hello, Gemini!\")\n",
    "print(response.text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medibot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
